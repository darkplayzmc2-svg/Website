<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>AI Clipper — Smart Highlights (Engagement Detection)</title>
<style>
  *{box-sizing:border-box}
  body{
    margin:0;
    font-family:Inter,system-ui,Arial,sans-serif;
    background:linear-gradient(180deg,#070712,#020205);
    color:#e6feff;
    -webkit-font-smoothing:antialiased;
    -moz-osx-font-smoothing:grayscale;
    overflow:hidden;
  }

  /* Upload / Controls screen */
  .overlay {
    position:fixed;inset:0;display:flex;align-items:center;justify-content:center;z-index:20;
  }
  .panel{
    width:320px;background:rgba(255,255,255,0.03);border:1px solid rgba(0,255,255,0.12);
    padding:18px;border-radius:12px;backdrop-filter:blur(6px);text-align:center;
  }
  .panel h1{margin:0 0 8px;font-size:20px;color:#bffcff}
  .panel p{margin:0 0 12px;color:#95f2ef;font-size:13px}
  label.input{
    display:flex;gap:8px;align-items:center;justify-content:space-between;margin-bottom:10px;
  }
  input[type=number]{
    width:120px;padding:8px;border-radius:8px;border:1px solid rgba(0,255,255,0.12);
    background:#000;color:#bffcff;font-weight:600;text-align:center;
  }
  .btn{
    display:inline-block;padding:10px 14px;border-radius:10px;border:1px solid #00e6e6;
    background:#071017;color:#001d1f;font-weight:700;cursor:pointer;
  }
  .btn:hover{filter:brightness(1.05)}

  .status{
    margin-top:12px;font-size:13px;color:#9ff0ec;height:20px;
  }

  /* Feed */
  .feed{
    position:relative;height:100vh;overflow-y:scroll;scroll-snap-type:y mandatory;
    -webkit-overflow-scrolling:touch;
  }
  .clip{
    scroll-snap-align:start;height:100vh;position:relative;display:flex;align-items:center;justify-content:center;background:#000;
  }
  video{
    max-height:100%;height:100%;width:auto;object-fit:cover;background:#000;
  }

  /* Floating controls */
  .controls {
    position:absolute;right:18px;bottom:72px;display:flex;flex-direction:column;gap:10px;
  }
  .control{
    width:120px;height:44px;border-radius:10px;background:rgba(255,255,255,0.04);
    border:1px solid rgba(0,255,255,0.12);display:flex;align-items:center;justify-content:center;
    font-weight:700;color:#c9fffb;cursor:pointer;backdrop-filter:blur(4px);
  }
  .control.recording{background:linear-gradient(90deg,#ff4d4d,#ff9a9a);color:#050005}
  .control:active{transform:scale(.98)}
  .recording-dot{width:10px;height:10px;border-radius:50%;background:#ff2b2b;margin-right:8px;box-shadow:0 0 6px #ff7b7b}

  /* small helpers */
  .muted-tag{font-size:12px;color:#9cc;opacity:.9;margin-top:6px}
  .small{font-size:13px;color:#9ff0ec}
</style>
</head>
<body>

<!-- Upload / options overlay -->
<div class="overlay" id="overlay">
  <div class="panel" id="panel">
    <h1>AI Clipper — Smart Highlights</h1>
    <p>Upload a video and the AI will extract the most engaging moments (audio-driven).</p>

    <div style="margin-bottom:10px">
      <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:6px">
        <label class="small">Clips</label>
        <input id="clipCount" type="number" min="1" max="12" value="5" />
      </div>
      <div style="display:flex;justify-content:space-between;align-items:center">
        <label class="small">Clip length (s)</label>
        <input id="clipLength" type="number" min="3" max="30" value="7" />
      </div>
    </div>

    <label class="btn" id="uploadLabel">Choose video
      <input id="fileInput" type="file" accept="video/*" style="display:none" />
    </label>

    <div style="margin-top:12px">
      <button class="btn" id="analyzeBtn" style="display:none">Analyze & Generate</button>
    </div>

    <div class="status" id="status">Ready</div>
    <div style="margin-top:10px;font-size:12px;color:#88e6e0">Note: downloads saved as webm (browser-encoded)</div>
  </div>
</div>

<!-- Vertical feed -->
<div id="feed" class="feed" style="display:none"></div>

<script>
/*
  AI Clipper — engagement detection by audio-energy peaks
  - Decode audio from file (AudioContext.decodeAudioData)
  - Compute short-time energy over windows (windowSec = 0.25)
  - Find top peaks with non-maximum suppression (minDistance)
  - For each selected peak create clip centered at peak (length chosen)
  - Render vertical feed; each clip uses <video src="blob#t=..."> for preview
  - Download records the played segment via captureStream + MediaRecorder and saves webm
*/

const fileInput = document.getElementById('fileInput');
const uploadLabel = document.getElementById('uploadLabel');
const analyzeBtn = document.getElementById('analyzeBtn');
const statusEl = document.getElementById('status');
const feed = document.getElementById('feed');
const overlay = document.getElementById('overlay');

let uploadedFile = null;
let audioBufferGlobal = null;
let objectUrl = null;

// user controls
const clipCountEl = document.getElementById('clipCount');
const clipLengthEl = document.getElementById('clipLength');

fileInput.addEventListener('change', (e) => {
  const f = e.target.files[0];
  if(!f) return;
  uploadedFile = f;
  statusEl.textContent = `Selected: ${f.name} (${(f.size/1024/1024).toFixed(2)} MB)`;
  analyzeBtn.style.display = 'inline-block';
});

// analysis button
analyzeBtn.addEventListener('click', async () => {
  if (!uploadedFile) return alert('Please choose a video file first.');
  analyzeBtn.disabled = true;
  statusEl.textContent = 'Loading file and extracting audio…';
  try {
    // load file as ArrayBuffer
    const arrayBuffer = await uploadedFile.arrayBuffer();

    // decode audio (use OfflineAudioContext for larger files)
    const audioCtx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(1, 1, 44100);
    const decoded = await audioCtx.decodeAudioData(arrayBuffer.slice(0));
    audioBufferGlobal = decoded;
    statusEl.textContent = 'Analyzing audio for high-energy segments…';
    await new Promise(r => setTimeout(r, 200)); // small pause

    // compute energy curve
    const clipLength = Math.max(3, parseFloat(clipLengthEl.value) || 7);
    const clipCount = Math.max(1, Math.min(12, parseInt(clipCountEl.value) || 5));
    const peaks = findEngagingPeaks(decoded, clipCount, clipLength);
    statusEl.textContent = `Detected ${peaks.length} highlight(s). Generating clips…`;

    // create object URL for previewing video
    if (objectUrl) URL.revokeObjectURL(objectUrl);
    objectUrl = URL.createObjectURL(uploadedFile);

    // create feed clips
    await generateClipsFromPeaks(objectUrl, peaks, clipLength);

    // hide overlay
    overlay.style.display = 'none';
    feed.style.display = 'block';
    statusEl.textContent = 'Done — scroll to view highlights';
  } catch (err) {
    console.error(err);
    alert('Error analyzing file: ' + err.message);
    statusEl.textContent = 'Error';
  } finally {
    analyzeBtn.disabled = false;
  }
});

/* ---------- Audio analysis ---------- */
function findEngagingPeaks(audioBuffer, desiredCount, clipLength) {
  // Compute mono signal
  const channel = audioBuffer.numberOfChannels > 0 ? audioBuffer.getChannelData(0) : audioBuffer.getChannelData(0);
  const sr = audioBuffer.sampleRate;

  // Energy window in seconds
  const windowSec = 0.25; // short window to detect transient energy
  const hopSec = 0.12;
  const winSize = Math.floor(windowSec * sr);
  const hopSize = Math.floor(hopSec * sr);
  const energies = [];
  const times = [];

  for (let pos = 0; pos + winSize < channel.length; pos += hopSize) {
    let sum = 0;
    for (let i = pos; i < pos + winSize; i++) {
      const s = channel[i];
      sum += s * s;
    }
    const rms = Math.sqrt(sum / winSize);
    energies.push(rms);
    times.push(pos / sr);
  }

  // find peaks: score = energy * local-contrast
  const scores = energies.map((e, i) => {
    // local average around +/- 4 hops
    const r = 4;
    let sum = 0, cnt = 0;
    for (let k = Math.max(0, i - r); k <= Math.min(energies.length - 1, i + r); k++) {
      sum += energies[k]; cnt++;
    }
    const localAvg = sum / cnt;
    return e - localAvg * 0.6; // favor energy above local average
  });

  // create array of {time,score} and sort by score
  const arr = scores.map((s, i) => ({time: times[i], score: s})).filter(a => a.score > 0);

  arr.sort((a,b) => b.score - a.score);

  // select top peaks with min distance (non-maximum suppression)
  const minDist = Math.max(1, Math.floor((clipLength * 0.6))); // seconds
  const selected = [];
  for (let candidate of arr) {
    if (selected.length >= desiredCount) break;
    // ensure candidate is not too close to existing chosen ones
    let ok = true;
    for (let s of selected) {
      if (Math.abs(s.time - candidate.time) < minDist) { ok = false; break; }
    }
    if (ok) selected.push(candidate);
  }

  // if not enough peaks, fallback to evenly spaced times
  if (selected.length < desiredCount) {
    const totalSec = audioBuffer.duration;
    selected.length = 0;
    for (let i=0;i<desiredCount;i++){
      const t = Math.min(totalSec - 0.5, (i + 0.5) * totalSec / desiredCount);
      selected.push({time: t, score: 0});
    }
  }

  // sort by time ascending
  selected.sort((a,b)=>a.time-b.time);

  // convert to clip start times (center clip on peak)
  const clipStarts = selected.map(s => {
    let start = s.time - clipLength/2;
    if (start < 0) start = 0;
    // ensure not beyond file
    if (start + clipLength > audioBuffer.duration) start = Math.max(0, audioBuffer.duration - clipLength);
    return {start: start, score: s.score};
  });

  return clipStarts;
}

/* ---------- Generate feed + clips ---------- */
async function generateClipsFromPeaks(objectUrl, peaks, clipLength) {
  feed.innerHTML = '';

  for (let i = 0; i < peaks.length; i++) {
    const {start} = peaks[i];
    const end = start + clipLength;
    const clipEl = document.createElement('div');
    clipEl.className = 'clip';

    // video element (for preview). Use #t= to hint browser start point
    // Note: some browsers ignore end in fragment; preview will loop whole viewport but we'll use events to clamp
    const video = document.createElement('video');
    video.src = `${objectUrl}#t=${start},${end}`;
    video.setAttribute('playsinline','');
    video.setAttribute('webkit-playsinline','');
    video.setAttribute('preload','metadata');
    video.controls = false;
    video.loop = true;
    video.muted = true; // start muted
    video.style.maxWidth = '100%';
    clipEl.appendChild(video);

    // floating controls
    const controls = document.createElement('div');
    controls.className = 'controls';

    const playBtn = document.createElement('div');
    playBtn.className = 'control';
    playBtn.textContent = 'Play';
    playBtn.onclick = () => togglePlayFor(playBtn);

    const muteBtn = document.createElement('div');
    muteBtn.className = 'control';
    muteBtn.textContent = 'Unmute';
    muteBtn.onclick = () => toggleMuteFor(muteBtn);

    const downloadBtn = document.createElement('div');
    downloadBtn.className = 'control';
    downloadBtn.textContent = 'Download';
    downloadBtn.onclick = async () => {
      // visual feedback
      downloadBtn.classList.add('recording');
      const dot = document.createElement('span');
      dot.className = 'recording-dot';
      downloadBtn.prepend(dot);
      downloadBtn.textContent = 'Recording';
      try {
        await recordSegmentAndDownload(objectUrl, start, end, `AIClip_${i+1}.webm`);
      } catch (err) {
        console.error(err);
        alert('Recording failed: ' + err.message);
      } finally {
        // restore
        downloadBtn.classList.remove('recording');
        if (dot && dot.parentNode) dot.parentNode.removeChild(dot);
        downloadBtn.textContent = 'Download';
      }
    };

    controls.appendChild(playBtn);
    controls.appendChild(muteBtn);
    controls.appendChild(downloadBtn);

    clipEl.appendChild(controls);

    // small muted hint
    const mutedTag = document.createElement('div');
    mutedTag.className = 'muted-tag';
    mutedTag.textContent = 'Muted by default — tap Unmute to activate audio';
    mutedTag.style.position='absolute';
    mutedTag.style.left='18px';
    mutedTag.style.bottom='26px';
    mutedTag.style.color='#9ff0ec';
    clipEl.appendChild(mutedTag);

    feed.appendChild(clipEl);

    // hook element reference for control functions
    // attach dataset
    playBtn._video = video;
    muteBtn._video = video;

    // ensure video won't autoplay sound; preview starts paused — but auto-play first clip
    video.addEventListener('loadedmetadata', () => {
      // clamp duration if fragment ignored: try to control playback range
      video._clipStart = start;
      video._clipEnd = Math.min(end, video.duration || end);
    });

    // periodically ensure loop within desired window (in case fragment ignored)
    video.addEventListener('timeupdate', () => {
      if (typeof video._clipEnd === 'number' && video.currentTime > video._clipEnd - 0.05) {
        // loop back
        try { video.currentTime = Math.max(video._clipStart, 0); } catch(e){}
      }
    });

    // click toggles play/pause
    video.addEventListener('click', () => {
      if (video.paused) { video.play(); playBtn.textContent='Pause'; } else { video.pause(); playBtn.textContent='Play'; }
    });
  }

  // autoplay the first clip muted (user gesture from clicking Analyze counts)
  const firstVideo = feed.querySelector('video');
  if (firstVideo) {
    try { await firstVideo.play(); const pb = feed.querySelector('.control'); if(pb) pb.textContent='Pause'; } catch(e) {}
  }

  // auto-pause logic on scroll: play clip in viewport
  feed.addEventListener('scroll', () => {
    const vh = window.innerHeight;
    const videos = feed.querySelectorAll('video');
    videos.forEach(v => {
      const rect = v.getBoundingClientRect();
      if (rect.top >= 0 && rect.bottom <= vh) {
        if (v.paused) { v.play(); const btn = v.parentNode.querySelector('.control'); if(btn) btn.textContent='Pause'; }
      } else {
        if (!v.paused) { v.pause(); const btn = v.parentNode.querySelector('.control'); if(btn) btn.textContent='Play'; }
      }
    });
  });
}

/* ---------- UI helpers ---------- */
function togglePlayFor(btn) {
  const v = btn._video;
  if (!v) return;
  if (v.paused) {
    v.play(); btn.textContent = 'Pause';
  } else {
    v.pause(); btn.textContent = 'Play';
  }
}
function toggleMuteFor(btn) {
  const v = btn._video;
  if (!v) return;
  v.muted = !v.muted;
  btn.textContent = v.muted ? 'Unmute' : 'Mute';
}

/* ---------- Recording (captureStream + MediaRecorder) ---------- */
async function recordSegmentAndDownload(srcUrl, startSec, endSec, filename) {
  // Create an offscreen video element to play the exact segment
  return new Promise(async (resolve, reject) => {
    const v = document.createElement('video');
    v.src = `${srcUrl}#t=${startSec},${endSec}`; // hint
    v.muted = false;
    v.playsInline = true;
    v.crossOrigin = 'anonymous';

    let stream;
    let recorder;
    let chunks = [];

    v.addEventListener('loadedmetadata', async () => {
      // Some browsers ignore #t end; we'll control playback manually
      const clipStart = startSec;
      const clipEnd = Math.min(endSec, v.duration || endSec);

      // seek to start
      try {
        v.currentTime = clipStart;
      } catch(e){
        // ignore
      }

      // wait for seeked
      v.addEventListener('seeked', async function onseek(){
        v.removeEventListener('seeked', onseek);
        // capture stream (audio+video) from video element
        try {
          stream = v.captureStream();
        } catch (err) {
          reject(new Error('captureStream not supported in this browser.'));
          return;
        }

        // start recording
        try {
          recorder = new MediaRecorder(stream, {mimeType: 'video/webm; codecs=vp8,opus'});
        } catch (err) {
          reject(new Error('MediaRecorder not available or codec unsupported: ' + err.message));
          return;
        }

        recorder.ondataavailable = e => { if (e.data && e.data.size) chunks.push(e.data); };
        recorder.onstop = async () => {
          const blob = new Blob(chunks, {type:'video/webm'});
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = filename;
          document.body.appendChild(a);
          a.click();
          a.remove();
          setTimeout(()=>URL.revokeObjectURL(url), 2000);
          resolve(blob);
        };

        // play video (may require user gesture - upload/Analyze counts)
        try {
          await v.play();
        } catch(err){
          // autoplay with sound may be blocked — play muted to start then unmute?
          v.muted = true;
          try { await v.play(); } catch(e){}
        }

        recorder.start(100); // collect every 100ms

        // stop recording after duration
        const duration = Math.max(0.1, clipEnd - clipStart);
        setTimeout(async () => {
          try {
            recorder.stop();
          } catch(e){}
          try { v.pause(); } catch(e){}
          resolve();
        }, Math.ceil(duration * 1000 + 200)); // slight buffer
      });
    });

    // error handlers
    v.onerror = (ev) => reject(new Error('Failed to load video for recording.'));
    // append offscreen to DOM to ensure captureStream works in some browsers
    v.style.position='fixed'; v.style.left='-20000px'; v.style.top='-20000px';
    document.body.appendChild(v);
    // cleanup after finish: remove element after some time
    setTimeout(()=>{ try{ if (v.parentNode) v.parentNode.removeChild(v);}catch(e){} }, 6000);
  });
}

</script>
</body>
</html>
